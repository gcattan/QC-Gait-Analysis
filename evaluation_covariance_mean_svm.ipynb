{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyriemann_qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QClass]  Initializing Quantum Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanolmos/opt/anaconda3/envs/dl/lib/python3.9/site-packages/pyriemann_qiskit/datasets/utils.py:11: UserWarning: mne not available. get_mne_sample will fail.\n",
      "  warn(\"mne not available. get_mne_sample will fail.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.utils import *\n",
    "from src.covariance_means import generalized_eigenvalue_covariance_mean\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split, KFold, StratifiedShuffleSplit, StratifiedGroupKFold, GroupKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from pyriemann.spatialfilters import CSP, SPoC\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "\n",
    "from pyriemann_qiskit.classification import QuanticSVM, QuanticNCH\n",
    "from pyriemann_qiskit.utils.hyper_params_factory import gen_x_feature_map, gen_z_feature_map\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process, using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_control_subjects, trainval_parkinson_subjects, test_control_subjects, test_parkinson_subjects, subject_covariances = load_and_split_subjects_by_group(pickle_file_path='data/densetnet201-4-CovsDict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_control_covs = calculate_mean_covariances_per_subject(subject_covariances = subject_covariances,\n",
    "                                                               ids = trainval_control_subjects)\n",
    "trainval_parkinnson_covs = calculate_mean_covariances_per_subject(subject_covariances = subject_covariances,\n",
    "                                                                    ids = trainval_parkinson_subjects)\n",
    "test_control_covs = calculate_mean_covariances_per_subject(subject_covariances = subject_covariances,\n",
    "                                                            ids = test_control_subjects)\n",
    "test_parkinson_covs = calculate_mean_covariances_per_subject(subject_covariances = subject_covariances,\n",
    "                                                             ids = test_parkinson_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dictionaries\n",
    "trainval_covs = {**trainval_control_covs, **trainval_parkinnson_covs}\n",
    "test_covs = {**test_control_covs, **test_parkinson_covs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subjects have exactly 8 videos.\n",
      "All subjects have exactly 8 videos.\n",
      "All subjects have exactly 8 videos.\n",
      "Subject PG_0028 has 16 videos\n",
      "Subject PG_0029 has 16 videos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_subject_video_count(trainval_control_covs)\n",
    "check_subject_video_count(trainval_parkinnson_covs)\n",
    "check_subject_video_count(test_control_covs)\n",
    "check_subject_video_count(test_parkinson_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/validation data...\n",
      "X shape: (176, 20, 20), y shape: (176,), ids shape: (176,), groups shape: (176,)\n",
      "Test data...\n",
      "X shape: (136, 20, 20), y shape: (136,), ids shape: (136,), groups shape: (136,)\n"
     ]
    }
   ],
   "source": [
    "# Creating the X, y arrays only for training_val subset\n",
    "X_trainval, y_trainval, ids_trainval, groups_trainval = create_X_y_groups_arrays(trainval_covs)\n",
    "print(f'Training/validation data...')\n",
    "print(f\"X shape: {X_trainval.shape}, y shape: {y_trainval.shape}, ids shape: {ids_trainval.shape}, groups shape: {groups_trainval.shape}\")\n",
    "\n",
    "X_test, y_test, ids_test, groups_test = create_X_y_groups_arrays(test_covs)\n",
    "print(f'Test data...')\n",
    "print(f\"X shape: {X_test.shape}, y shape: {y_test.shape}, ids shape: {ids_test.shape}, groups shape: {groups_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QClass]  Initializing Quantum Classifier\n"
     ]
    }
   ],
   "source": [
    "# Define spatial filter\n",
    "spatial_filter = CSP(nfilter=4, log=False)\n",
    "\n",
    "# Define metric\n",
    "METRIC = \"logeuclid\"\n",
    "# define pipelines:\n",
    "\n",
    "\n",
    "pipeline_classical = make_pipeline(\n",
    "    spatial_filter,\n",
    "    TangentSpace(metric=METRIC),\n",
    "    svm.SVC()\n",
    ")\n",
    "\n",
    "\n",
    "pipe_ts_qsvm2 = make_pipeline(\n",
    "    # Whitening(metric=\"logeuclid\", dim_red={'n_components': 2}),\n",
    "    # PCA_SPD(n_components=2),\n",
    "    spatial_filter,\n",
    "    TangentSpace(metric=METRIC),\n",
    "    QuanticSVM(gen_feature_map=gen_x_feature_map(reps=2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores svm: 0.990625 [0.96875 1.      1.      1.      1.      1.      0.9375  1.      1.\n",
      " 1.     ]\n",
      "scores svm all: 0.8354166666666668 [0.5        0.5        0.875      1.         0.85416667 1.\n",
      " 0.875      1.         0.75       1.        ]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "# Scores training only on training/validation dataset\n",
    "scores_svm = cross_val_score(estimator = pipeline_classical, \n",
    "                             X = X_trainval,\n",
    "                             y = y_trainval,\n",
    "                             scoring=\"balanced_accuracy\", \n",
    "                             cv=cv, groups=groups_trainval)\n",
    "\n",
    "print(f'scores svm: {scores_svm.mean()} {scores_svm}')\n",
    "\n",
    "# Scores with all data\n",
    "X_all, y_all, ids_all, groups_all = np.concatenate([X_trainval, X_test]), np.concatenate([y_trainval, y_test]), np.concatenate([ids_trainval, ids_test]), np.concatenate([groups_trainval, groups_test])\n",
    "scores_svm_all = cross_val_score(estimator = pipeline_classical,\n",
    "                                    X = X_all,\n",
    "                                    y = y_all,\n",
    "                                    scoring=\"balanced_accuracy\",\n",
    "                                    cv=cv, groups=groups_all)\n",
    "print(f'scores svm all: {scores_svm_all.mean()} {scores_svm_all}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedGroupKFold(n_splits=10)\n",
    "# models = []\n",
    "# scores = []\n",
    "\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups)):    \n",
    "#     # Split the data\n",
    "#     # print(f'Test ids: {ids[test_idx]}')\n",
    "#     X_train, X_test = X[train_idx], X[test_idx]\n",
    "#     y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "#     # Clone the model\n",
    "#     model = clone(pipeline_classical)\n",
    "    \n",
    "#     # Fit the model on the training data\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Save the trained model\n",
    "#     models.append(model)\n",
    "    \n",
    "#     # Evaluate the model on the validation data\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     score = balanced_accuracy_score(y_test, y_pred)\n",
    "#     scores.append(score)\n",
    "    \n",
    "#     # print(f\"Fold {fold + 1} balanced accuracy score: {score}\")\n",
    "\n",
    "# print(f'Avg scores: {np.mean(scores)} | Scores: {scores}')\n",
    "\n",
    "# y_preds = []\n",
    "# for idx, model in enumerate(models):\n",
    "#     predictions = model.predict(X_test)\n",
    "#     y_preds.append(predictions)\n",
    "#     # print(f\"Predictions from model {idx + 1}: {predictions}\")\n",
    "# y_preds = np.array(y_preds)\n",
    "# final_preds = mode(y_preds, axis=0)[0].flatten() # Get the majority vote prediction\n",
    "\n",
    "# score_test = balanced_accuracy_score(y_test, final_preds)\n",
    "# print(f\"Final test score: {score_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
